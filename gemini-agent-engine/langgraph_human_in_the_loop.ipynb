{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The previous [notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb) covered: Defining Tools, Defining a Router, Building a LangGraph Application, Local Testing, Deploying to Vertex AI, Remote Testing, and Cleaning Up Resources.\n",
    "\n",
    "\n",
    "- **Reviewing Tool Calls:** Implement human oversight after tool use, allowing for verification and correction of actions before proceeding.\n",
    "- **Fetching State History:** Retrieve the complete execution history of the LangGraph application for auditing, analysis, and potential state reversion.\n",
    "- **Time Travel:** Examine the state of the agent at a specific point in time to understand past decisions.\n",
    "- **Replay:** Restart execution from a specific checkpoint without modifications to ensure consistent results.\n",
    "- **Branching:** Create alternative execution paths based on a past state, enabling the agent to explore different possibilities or correct previous errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "source": [
    "#### Copyright 2025 Google LLC\n",
    "(https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/langgraph_human_in_the_loop.ipynb)\n",
    "(https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --user --quiet \"google-cloud-aiplatform[agent_engines,langchain]\" requests --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import vertexai\n",
    "from langchain.load import load as langchain_load\n",
    "import requests\n",
    "from vertexai import agent_engines\n",
    "from vertexai.preview.reasoning_engines import LangchainAgent, LanggraphAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"llm-studies\"\n",
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs:// human-in-the-loop-lq\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9AhaLYidDzQu"
   },
   "outputs": [],
   "source": [
    "def get_exchange_rate(\n",
    "    currency_from: str = \"USD\",\n",
    "    currency_to: str = \"EUR\",\n",
    "    currency_date: str = \"latest\",\n",
    "):\n",
    "    \"\"\"Retrieves the exchange rate between two currencies on a specified date.\n",
    "\n",
    "    Uses the Frankfurter API (https://api.frankfurter.app/) to obtain\n",
    "    exchange rate data.\n",
    "\n",
    "    Args:\n",
    "        currency_from: The base currency (3-letter currency code).\n",
    "            Defaults to \"USD\" (US Dollar).\n",
    "        currency_to: The target currency (3-letter currency code).\n",
    "            Defaults to \"EUR\" (Euro).\n",
    "        currency_date: The date for which to retrieve the exchange rate.\n",
    "            Defaults to \"latest\" for the most recent exchange rate data.\n",
    "            Can be specified in YYYY-MM-DD format for historical rates.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the exchange rate information.\n",
    "            Example: {\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2023-11-24\",\n",
    "                \"rates\": {\"EUR\": 0.95534}}\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"https://api.frankfurter.app/{currency_date}\",\n",
    "        params={\"from\": currency_from, \"to\": currency_to},\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "22981b2e1c59"
   },
   "outputs": [],
   "source": [
    "checkpointer_kwargs = None\n",
    "def checkpointer_builder(**kwargs):\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    "    return MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6eeff14856cd"
   },
   "outputs": [],
   "source": [
    "agent = LanggraphAgent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    tools=[get_exchange_rate],\n",
    "    model_kwargs={\"temperature\": 0, \"max_retries\": 6},\n",
    "    checkpointer_kwargs=checkpointer_kwargs,\n",
    "    checkpointer_builder=checkpointer_builder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oOJMqctkVvYA"
   },
   "outputs": [],
   "source": [
    "agent.set_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JHU5GhMrh6Xz"
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"What is the exchange rate from US dollars to Swedish currency?\")\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aA5s9KI2VwJv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could you please specify the symbols or the names of the currencies you are interested in? Also, do you have a specific date for the exchange rate you want to know? If not, I will use the latest available data.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    input=inputs,\n",
    "    config={\"configurable\": {\"thread_id\": \"synchronous-thread-id\"}},\n",
    ")\n",
    "\n",
    "response[\"messages\"][-1][\"kwargs\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fc70cda0aeb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is the exchange rate from US dollars to Swedish currency?', 'type': 'human', 'id': 'ed68c05b-67a7-48a3-b4f3-9ebf3059685d'}}]}\n",
      "{'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'What is the exchange rate from US dollars to Swedish currency?', 'type': 'human', 'id': 'ed68c05b-67a7-48a3-b4f3-9ebf3059685d'}}, {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Could you please specify the symbols or the full name of the Swedish currency you are interested in?\\n', 'response_metadata': {'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 134, 'candidates_token_count': 20, 'total_token_count': 154, 'prompt_tokens_details': [{'modality': 1, 'token_count': 134}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 20}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0729248046875, 'model_name': 'gemini-2.0-flash'}, 'type': 'ai', 'id': 'run-77684a6b-113a-403a-ad07-2c4417dad701-0', 'usage_metadata': {'input_tokens': 134, 'output_tokens': 20, 'total_tokens': 154}, 'tool_calls': [], 'invalid_tool_calls': []}}]}\n"
     ]
    }
   ],
   "source": [
    "for state_values in agent.stream_query(\n",
    "    input=inputs,\n",
    "    stream_mode=\"values\",\n",
    "    config={\"configurable\": {\"thread_id\": \"streaming-thread-values\"}},\n",
    "):\n",
    "    print(state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "K4IjUrV_E3pc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Could you please specify the symbols or the full name of the Swedish currency you are interested in?\\n', 'response_metadata': {'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 134, 'candidates_token_count': 20, 'total_token_count': 154, 'prompt_tokens_details': [{'modality': 1, 'token_count': 134}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 20}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0729248046875, 'model_name': 'gemini-2.0-flash'}, 'type': 'ai', 'id': 'run-d8a5cd7f-94dc-433b-91bb-ce7ff96a1e6a-0', 'usage_metadata': {'input_tokens': 134, 'output_tokens': 20, 'total_tokens': 154}, 'tool_calls': [], 'invalid_tool_calls': []}}]}}\n"
     ]
    }
   ],
   "source": [
    "for state_updates in agent.stream_query(\n",
    "    input=inputs,\n",
    "    stream_mode=\"updates\",\n",
    "    config={\"configurable\": {\"thread_id\": \"streaming-thread-updates\"}},\n",
    "):\n",
    "    print(state_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-uvK9JJokfou"
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=inputs,\n",
    "    interrupt_before=[\"tools\"],  # Before invoking the tool.\n",
    "    interrupt_after=[\"tools\"],  # After getting a tool message.\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    ")\n",
    "langchain_load(response[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-45J2HOaSfWb"
   },
   "source": [
    "The process was interrupted *before invoking the tool*.\n",
    "\n",
    "After review, we assume the LLM-generated tool call (`AI Message`) is correct and proceed to resume execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4YHPNebpkfrU"
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=None,  # Resume (continue with the tool call AI Message).\n",
    "    interrupt_before=[\"tools\"],\n",
    "    interrupt_after=[\"tools\"],\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    ")\n",
    "langchain_load(response[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCVylqwzUSfm"
   },
   "source": [
    "The process is interrupted again *after receiving the tool message*.\n",
    "\n",
    "Upon review, if the LLM-generated `Tool Message` appears correct, we can resume execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "i8wAJxyykfuI"
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=None,  # Resume (continue with the Tool Message).\n",
    "    interrupt_before=[\"tools\"],\n",
    "    interrupt_after=[\"tools\"],\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    ")\n",
    "langchain_load(response[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf0msu8l1Z6v"
   },
   "source": [
    "### Fetching State History\n",
    "\n",
    "You can fetch the state history by calling `.get_state_history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7Kp9eqFv1fTA"
   },
   "outputs": [],
   "source": [
    "for state_snapshot in agent.get_state_history(\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    "):\n",
    "    if state_snapshot[\"metadata\"][\"step\"] >= 0:\n",
    "        print(f'step {state_snapshot[\"metadata\"][\"step\"]}: {state_snapshot[\"config\"]}')\n",
    "        state_snapshot[\"values\"][\"messages\"][-1].pretty_print()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg72Af3U1_Im"
   },
   "source": [
    "### Time Travel\n",
    "\n",
    "LangGraph's [Time Travel](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/) demonstrates how to build a conversational agent with persistent memory, enabling human intervention to correct past actions.  Essentially, it \"rewinds\" the conversation to a previous state, allows for mistake correction, and permits the agent to continue from that corrected point.\n",
    "\n",
    "You can \"time travel\" by calling `.get_state`. By default, the agent retrieves the `latest state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UxeCODgILFN3"
   },
   "outputs": [],
   "source": [
    "state = agent.get_state(\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"human-in-the-loop-deepdive\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f'step {state[\"metadata\"][\"step\"]}: {state[\"config\"]}')\n",
    "state[\"values\"][\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dT7W34i2opn"
   },
   "source": [
    "To retrieve an earlier state, you need to specify the `checkpoint_id` (and `checkpoint_ns`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wHK72zjAtbZi"
   },
   "outputs": [],
   "source": [
    "snapshot_config = {}\n",
    "for state_snapshot in agent.get_state_history(\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    "):\n",
    "    if state_snapshot[\"metadata\"][\"step\"] == 1:\n",
    "        snapshot_config = state_snapshot[\"config\"]\n",
    "        break\n",
    "\n",
    "snapshot_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hpl-ElG72LUt"
   },
   "outputs": [],
   "source": [
    "state = agent.get_state(config=snapshot_config)\n",
    "print(f'step {state[\"metadata\"][\"step\"]}: {state[\"config\"]}')\n",
    "state[\"values\"][\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "j86TZj1s2cGW"
   },
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su91f3u02ytT"
   },
   "source": [
    "### Replay\n",
    "\n",
    "LangGraph's [Replay](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/#replay-a-state) feature allows you to resume or replay a conversation from any specific point in its history.\n",
    "\n",
    "You can initiate a replay by passing the `state[\"config\"]` back to the agent. Note that the execution resumes exactly where it was left off, executing a tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-OTMr3Fe7kig"
   },
   "outputs": [],
   "source": [
    "state[\"config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l5FfylrfrYAJ"
   },
   "outputs": [],
   "source": [
    "for state_values in agent.stream_query(\n",
    "    input=None,  # resume\n",
    "    stream_mode=\"values\",\n",
    "    config=state[\"config\"],\n",
    "):\n",
    "    langchain_load(state_values[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGJSM__V3zvS"
   },
   "source": [
    "### Branching\n",
    "\n",
    "LangGraph's [Branching](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/#branch-off-a-past-state) feature allows you to modify and re-run a LangGraph conversation from a specific point in its history (rather than just from the latest state).  This enables the agent to explore alternate trajectories or allows a user to \"version control\" changes in a workflow.\n",
    "\n",
    "In this example, you will:\n",
    "* Update the tool calls from a previous step.\n",
    "* Call `.update_state` to rerun the step with the updated configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Is1Ca-QE8P6T"
   },
   "outputs": [],
   "source": [
    "last_message = state[\"values\"][\"messages\"][-1]\n",
    "print(last_message)\n",
    "print(last_message.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLBeJAOIcPWI"
   },
   "source": [
    "Update the tool calls from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jP3cHIrF8VfW"
   },
   "outputs": [],
   "source": [
    "last_message.tool_calls[0][\"args\"][\"currency_date\"] = \"2024-09-01\"\n",
    "last_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HZovMHe_cfX"
   },
   "source": [
    "Call `.update_state` to rerun the step with the updated configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qB45N3eL9XiP"
   },
   "outputs": [],
   "source": [
    "branch_config = agent.update_state(\n",
    "    config=state[\"config\"],\n",
    "    values={\"messages\": [last_message]},  # the update we want to make\n",
    ")\n",
    "branch_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zWS9Sk_h9p8I"
   },
   "outputs": [],
   "source": [
    "for state_values in agent.stream_query(\n",
    "    input=None,  # resume\n",
    "    stream_mode=\"values\",\n",
    "    config=branch_config,\n",
    "):\n",
    "    langchain_load(state_values[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOYFDvqFGNqg"
   },
   "source": [
    "## Deploying the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xi-3p8Wd0r4x"
   },
   "outputs": [],
   "source": [
    "remote_agent = agent_engines.create(\n",
    "    LanggraphAgent(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        tools=[get_exchange_rate],\n",
    "        model_kwargs={\"temperature\": 0, \"max_retries\": 6},\n",
    "        checkpointer_kwargs=checkpointer_kwargs,\n",
    "        checkpointer_builder=checkpointer_builder,\n",
    "    ),\n",
    "    requirements=[\n",
    "        \"google-cloud-aiplatform[agent_engines,langchain]\",\n",
    "        \"requests\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "remote_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqt-TOmEGLL8"
   },
   "source": [
    "## Querying the Remote Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g6lOlZSsdmD"
   },
   "source": [
    "### Remote testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HlbK3Bsq3LlE"
   },
   "outputs": [],
   "source": [
    "for state_updates in remote_agent.stream_query(\n",
    "    input=inputs,\n",
    "    stream_mode=\"updates\",\n",
    "    config={\"configurable\": {\"thread_id\": \"remote-streaming-thread-updates\"}},\n",
    "):\n",
    "    print(state_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YQE8Rfyz1jcA"
   },
   "outputs": [],
   "source": [
    "for state_values in remote_agent.stream_query(\n",
    "    input=inputs,\n",
    "    stream_mode=\"values\",\n",
    "    config={\"configurable\": {\"thread_id\": \"remote-human-in-the-loop-overall\"}},\n",
    "):\n",
    "    print(state_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7ocljPjUXYx"
   },
   "source": [
    "### Reviewing Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_LB3KXTUUas7"
   },
   "outputs": [],
   "source": [
    "response = remote_agent.query(\n",
    "    input=inputs,\n",
    "    interrupt_before=[\"tools\"],  # Before invoking the tool.\n",
    "    interrupt_after=[\"tools\"],  # After getting a tool message.\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    ")\n",
    "langchain_load(response[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "smWg54uqUs0g"
   },
   "outputs": [],
   "source": [
    "response = remote_agent.query(\n",
    "    input=None,  # Resume (continue with the tool call AI Message).\n",
    "    interrupt_before=[\"tools\"],\n",
    "    interrupt_after=[\"tools\"],\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    ")\n",
    "langchain_load(response[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QRE3BCvRU0nC"
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    input=None,  # Resume (continue with the Tool Message).\n",
    "    interrupt_before=[\"tools\"],\n",
    "    interrupt_after=[\"tools\"],\n",
    "    config={\"configurable\": {\"thread_id\": \"human-in-the-loop-deepdive\"}},\n",
    ")\n",
    "langchain_load(response[\"messages\"][-1]).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4e033321ad"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "After you've finished experimenting, it's a good practice to clean up your cloud resources. You can delete the deployed Agent Engine instance to avoid any unexpected charges on your Google Cloud account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "eb5fbfa43866"
   },
   "outputs": [],
   "source": [
    "remote_agent.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "No17Cw5hgx12",
    "R5Xep4W9lq-Z",
    "dmWOrTJ3gx13",
    "DF4l8DTdWgPY"
   ],
   "name": "langgraph_human_in_the_loop.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
