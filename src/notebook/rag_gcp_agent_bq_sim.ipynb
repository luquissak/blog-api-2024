{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57137f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3631ad75-377a-4de0-b60f-135097baa958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5822611-bc3e-4289-b089-500f78f1ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_community import BigQueryVectorStore\n",
    "from langchain import hub\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8bdc582-ee1a-4bbb-84fc-68832aa90b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\") \n",
    "LOCATION = os.getenv(\"EMB_LOCATION\") \n",
    "DATASET = os.getenv(\"DATASET\") \n",
    "TABLE = os.getenv(\"TABLE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4b6fa5-7efe-4139-aa10-af124820e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = VertexAIEmbeddings(model=\"textembedding-gecko@latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0363e888-1d6b-4340-bdaa-78a8f667c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery table llm-studies.blog_embeddings.rag_embeddings initialized/validated as persistent storage. Access via BigQuery console:\n",
      " https://console.cloud.google.com/bigquery?project=llm-studies&ws=!1m5!1m4!4m3!1sllm-studies!2sblog_embeddings!3srag_embeddings\n"
     ]
    }
   ],
   "source": [
    "vector_store = BigQueryVectorStore(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_name=DATASET,\n",
    "    table_name=TABLE,\n",
    "    location=LOCATION,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3991f37e-6258-48e8-af60-bc3fe5c56fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = vector_store.similarity_search(\n",
    "    \"Dennett é um eliminativista?\",\n",
    "    k=2,\n",
    "    filter={\"doc_id\": \"4169c3a6102540149ae4d0de6cbf06f2\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9b6305c-bcf8-40f5-a5be-074704943ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dda3c51-58de-4ab7-ba68-502e11b08cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "question = \"Dennett é um eliminativista?\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd8dc1c3-87ae-4040-b089-14587048ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "prompt = prompt.invoke({\"question\": question, \"context\": docs_content})\n",
    "answer = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c46517ca-ec5b-4879-9f2b-01bf9d5f24c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eu não sei. O contexto fornecido não contém informação sobre a visão de Dennett sobre o eliminativismo.\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de020fbb-a688-4525-be63-14fec53eecbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a6475-8c21-4ac0-a086-d7326049ee52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973caea-0a9b-4f30-b459-476421e1223f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9712326-deb1-4009-8760-b6f390482950",
   "metadata": {},
   "source": [
    "#### Qual embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f5b59c-0319-462b-9d0f-615e8f4c4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE = \"rag_embeddings_s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae985c-9de6-4160-b188-a3e684ff90ea",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb185c8-edf2-45df-b340-362a62b77b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_community import BigQueryVectorStore\n",
    "import csv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88643848-a6ac-4384-9704-b948efea6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "assert \"LANGSMITH_TRACING\" in os.environ, \"Please set the LANGSMITH_TRACING environment variable.\"\n",
    "assert \"LANGSMITH_API_KEY\" in os.environ, \"Please set the LANGSMITH_API_KEY environment variable.\"\n",
    "assert \"PROJECT_ID\" in os.environ, \"Please set the PROJECT_ID environment variable.\"\n",
    "assert \"LOCATION\" in os.environ, \"Please set the LOCATION environment variable.\"\n",
    "assert \"DATASET\" in os.environ, \"Please set the DATASET environment variable.\"\n",
    "assert \"TABLE\" in os.environ, \"Please set the TABLE environment variable.\"\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\") \n",
    "LOCATION = os.getenv(\"LOCATION\") \n",
    "DATASET = os.getenv(\"DATASET\") \n",
    "TABLE = os.getenv(\"TABLE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2f1c55-a082-4397-89d7-86bf7792d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"llm-studies\"\n",
    "LOCATION = \"us-central1\"\n",
    "DATASET = \"blog_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c0c9ea-fe6d-457d-a813-90800f4f2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = VertexAIEmbeddings(model=\"textembedding-gecko@latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00f7952-6c84-4630-a662-da489c255157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery table llm-studies.blog_embeddings.rag_embeddings initialized/validated as persistent storage. Access via BigQuery console:\n",
      " https://console.cloud.google.com/bigquery?project=llm-studies&ws=!1m5!1m4!4m3!1sllm-studies!2sblog_embeddings!3srag_embeddings\n"
     ]
    }
   ],
   "source": [
    "vector_store = BigQueryVectorStore(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_name=DATASET,\n",
    "    table_name=TABLE,\n",
    "    location=LOCATION,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de7c0c0e-3f25-4def-bc28-c875a73b8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa77685-614a-4ed2-8237-3cdb16ff9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf4c88b-bcf3-4aec-8ddf-57045ce45a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c563e3c-75cd-481b-853c-655ca25eb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64671c-c1d1-4b56-8cf6-d305cbbabf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a82844-4998-4888-977e-a1f1f46a8891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b7947-09d6-4923-b7b9-fec596a4a7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "791d0859-bea3-413f-bd86-0b5dece01c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = ToolNode([retrieve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2c02e6-bcf1-42ef-9811-b41959eb8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e360a-0866-4a0b-aded-341107553c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3acc14ff-66f8-4251-9bf6-5212465db5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (18860e37-b95f-4ccc-8287-236514b6948b)\n",
      " Call ID: 18860e37-b95f-4ccc-8287-236514b6948b\n",
      "  Args:\n",
      "    query: Daniel Dennett eliminativism\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'doc_id': '701792560a3d49af8ed3e872610183de', 'source': 'https://www.reflexoesdofilosofo.blog.br/2025/01/heterofenomenologia.html', 'score': 0.6980907463376732}\n",
      "Content: constitui a essência da consciência. Ele propõe uma visão alternativa, que é baseada em uma abordagem materialista e funcionalista, onde a experiência subjetiva é vista como um conjunto de funções cerebrais e comportamentais, em vez de uma entidade metafísica.Pontos importantes sobre a visão de Dennett:Eliminativismo: Dennett é frequentemente associado ao eliminativismo, a visão de que conceitos como \"qualia\" e \"experiência subjetiva\" podem e devem ser eliminados da nossa linguagem e teoria da mente.Intencionalidade: Apesar de negar a experiência subjetiva no sentido tradicional, ele não nega que os seres humanos e outros animais tenham estados intencionais, ou seja, que se relacionam com o mundo através de crenças, desejos e intenções.O papel da linguagem: Ele enfatiza a importância da linguagem na construção da nossa compreensão da experiência. Ele argumenta que a nossa tendência de atribuir a nós mesmos e aos outros uma \"vida interior\" é uma construção linguística, que pode nos\n",
      "\n",
      "Source: {'doc_id': '4169c3a6102540149ae4d0de6cbf06f2', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/10/searle-contra-dennett.html', 'score': 0.725587326986408}\n",
      "Content: Searle contra Dennett*\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sim, Dennett é frequentemente associado ao eliminativismo, a visão de que conceitos como \"qualia\" e \"experiência subjetiva\" podem e devem ser eliminados da nossa linguagem e teoria da mente. Apesar de negar a experiência subjetiva no sentido tradicional, ele não nega que os seres humanos e outros animais tenham estados intencionais. Ele enfatiza a importância da linguagem na construção da nossa compreensão da experiência.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Dennett é um eliminativista?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}, {\"role\": \"system\", \"content\": \"Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c87d224-2ed1-49df-a2a9-a01bffbec620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (1f070483-f4e6-42b1-99c8-432e9a72735c)\n",
      " Call ID: 1f070483-f4e6-42b1-99c8-432e9a72735c\n",
      "  Args:\n",
      "    query: eliminativismo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'doc_id': 'fb7fcafa9ffe47269dbad63df4a0eb18', 'source': 'https://www.reflexoesdofilosofo.blog.br/2023/02/descritivismo.html', 'score': 0.6619441515696384}\n",
      "Content: Descritivismo\n",
      "\n",
      "Source: {'doc_id': '9afdd777f93a40b5a366da0d475c7ebb', 'source': 'https://www.reflexoesdofilosofo.blog.br/2022/12/referencialismo.html', 'score': 0.7284535514220247}\n",
      "Content: Referencialismo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Não tenho informações sobre quem é um eliminativista nos textos fornecidos.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Me fale quem é eliminativista\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}, {\"role\": \"system\", \"content\": \"Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6c5e8c-3be3-46d9-b753-bbdb8adb3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bd3a3-cc0c-4c3f-be89-27955b57858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d4c9e-2900-4190-8867-f90a3fc58971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
