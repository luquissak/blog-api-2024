{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57137f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ae985c-9de6-4160-b188-a3e684ff90ea",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb185c8-edf2-45df-b340-362a62b77b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_community import BigQueryVectorStore\n",
    "import csv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88643848-a6ac-4384-9704-b948efea6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "assert \"LANGSMITH_TRACING\" in os.environ, \"Please set the LANGSMITH_TRACING environment variable.\"\n",
    "assert \"LANGSMITH_API_KEY\" in os.environ, \"Please set the LANGSMITH_API_KEY environment variable.\"\n",
    "assert \"PROJECT_ID\" in os.environ, \"Please set the PROJECT_ID environment variable.\"\n",
    "assert \"LOCATION\" in os.environ, \"Please set the LOCATION environment variable.\"\n",
    "assert \"DATASET\" in os.environ, \"Please set the DATASET environment variable.\"\n",
    "assert \"TABLE\" in os.environ, \"Please set the TABLE environment variable.\"\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\") \n",
    "LOCATION = os.getenv(\"LOCATION\") \n",
    "DATASET = os.getenv(\"DATASET\") \n",
    "TABLE = os.getenv(\"TABLE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2f1c55-a082-4397-89d7-86bf7792d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"llm-studies\"\n",
    "LOCATION = \"us-central1\"\n",
    "DATASET = \"blog_embeddings\"\n",
    "TABLE = \"rag_embeddings_s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c0c9ea-fe6d-457d-a813-90800f4f2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = VertexAIEmbeddings(model=\"textembedding-gecko@latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00f7952-6c84-4630-a662-da489c255157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery table llm-studies.blog_embeddings.rag_embeddings_s initialized/validated as persistent storage. Access via BigQuery console:\n",
      " https://console.cloud.google.com/bigquery?project=llm-studies&ws=!1m5!1m4!4m3!1sllm-studies!2sblog_embeddings!3srag_embeddings_s\n"
     ]
    }
   ],
   "source": [
    "vector_store = BigQueryVectorStore(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_name=DATASET,\n",
    "    table_name=TABLE,\n",
    "    location=LOCATION,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23656086-2915-4869-ae10-b85f4c663ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reflexoesdofilosofo.blog.br/2025/02/o-problema-de-parmenides.html\n"
     ]
    }
   ],
   "source": [
    "url_list = []\n",
    "with open('.//..//..//files//20250207-posts_list-red.csv', 'r') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        url = str(row[0]).replace(\"http\",\"https\")\n",
    "        url_list.append(url)\n",
    "print(url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34fa8f9b-878c-46b1-b838-076be4716fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html\",\n",
    "#    \"https://www.reflexoesdofilosofo.blog.br/2024/09/uma-teoria-da-mente.html\",\n",
    "#    \"https://www.reflexoesdofilosofo.blog.br/2025/02/o-problema-de-parmenides.html\",\n",
    "]\n",
    "print(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f75dbb-8c3c-47a3-9930-b2fe39ccebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(urls),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post hentry uncustomized-post-template\", \"post-title entry-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bdff30d-8587-48e4-8108-115fc6ff59f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd62359d-1d36-4933-ad2d-5cf67797583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de7c0c0e-3f25-4def-bc28-c875a73b8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2274302a-272d-41d0-9bea-f79b1de8aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8566336-ea60-4fe1-b36f-f61ccd80f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21494e8c-0eff-4b27-9c2b-95d8949ca88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd774d7-dc7b-4451-8af6-61ae87f48ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f363e75-b9ad-4116-a2c1-e2fd57876bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84795ad6-8bc3-4d23-acd5-102e79beecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = ToolNode([retrieve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa77685-614a-4ed2-8237-3cdb16ff9a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae2c02e6-bcf1-42ef-9811-b41959eb8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3acc14ff-66f8-4251-9bf6-5212465db5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (f94c8c2b-8438-43ec-ae06-ae86477ba666)\n",
      " Call ID: f94c8c2b-8438-43ec-ae06-ae86477ba666\n",
      "  Args:\n",
      "    query: mente na filosofia\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'doc_id': '31d1c41043134682beff20f04797b1f8', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html', 'score': 0.6674564372885906}\n",
      "Content: [i] Com base na Introdução de A\n",
      "mente segundo Dennett, de, João de Fernandes Teixeira. São Paulo: Editora\n",
      "Perspectiva, 2008.\n",
      "\n",
      "\n",
      "[ii] “Ocorre\n",
      "que a posição cética, ao duvidar das afirmações e das coisas, pode colocar\n",
      "nossa existência em risco. Ora, como podemos viver duvidando de tudo? A\n",
      "resposta cética parece ser a de uma atitude filosófica: aceitamos as coisas da\n",
      "vida ordinária e vivemos nos baseando nela, porém dentro de uma atitude\n",
      "filosófica mantemos a dúvida.”. Em https://www.reflexoesdofilosofo.blog.br/2024/04/pesquisa-sobre-atitude-filosofica-cetica.html.\n",
      "\n",
      "\n",
      "[iii] Já em 2020 tínhamos problema com\n",
      "ela: https://www.reflexoesdofilosofo.blog.br/2020/03/uma-consciencia-uma-dificuldade.html. Na verdade, muito antes, na\n",
      "escola de filosofia.\n",
      "\n",
      "\n",
      "[iv] Ver https://quissak-en.blogspot.com/2018/08/are-you-conscious.html.\n",
      "\n",
      "Source: {'doc_id': 'a7e2d984b7744559bc107df1ef5765fa', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html', 'score': 0.7039613548549176}\n",
      "Content: [iv] Ver https://quissak-en.blogspot.com/2018/08/are-you-conscious.html.\n",
      "\n",
      "\n",
      "[v] Fizemos uma aproximação do\n",
      "pensamento de Chalmers, mas devemos aprofundar para compreender as colocações\n",
      "de Teixeira: https://www.reflexoesdofilosofo.blog.br/2016/05/a-informacao-como-lei-da-consciencia.html. \n",
      "\n",
      "\n",
      "[vi] Algo aqui: https://quissak-en.blogspot.com/2018/04/tech-to-study-braini.html.\n",
      "\n",
      "\n",
      "[vii] Vai valer a pena olharmos o “De\n",
      "anima”: https://www.editora34.com.br/detalhe.asp?id=340, “Primeiro estudo sistemático da\n",
      "psykhê, entendida aqui como o princípio vital comum a todos os seres animados,\n",
      "o tratado De Anima (literalmente, \"Sobre a Alma\") representa o ponto\n",
      "culminante da filosofia natural de Aristóteles e está na origem tanto da\n",
      "biologia quanto da psicologia como disciplinas teóricas.”\n",
      "\n",
      "\n",
      "[viii] Não nos esqueçamos das críticas de\n",
      "Dreyfus: https://www.reflexoesdofilosofo.blog.br/2020/06/ia-do-representacao-cognitiva-ao.html.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A mente é estudada na introdução de \"A mente segundo Dennett\", de João de Fernandes Teixeira. O \"De anima\" de Aristóteles é um estudo sistemático da psychê, o princípio vital comum a todos os seres animados. Este tratado está na origem da biologia e da psicologia como disciplinas teóricas.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"me fale sobre a mente\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}, {\"role\": \"system\", \"content\": \"Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87d224-2ed1-49df-a2a9-a01bffbec620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6c5e8c-3be3-46d9-b753-bbdb8adb3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bd3a3-cc0c-4c3f-be89-27955b57858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d4c9e-2900-4190-8867-f90a3fc58971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
