{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57137f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ae985c-9de6-4160-b188-a3e684ff90ea",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb185c8-edf2-45df-b340-362a62b77b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_community import BigQueryVectorStore\n",
    "import csv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88643848-a6ac-4384-9704-b948efea6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "assert \"LANGSMITH_TRACING\" in os.environ, \"Please set the LANGSMITH_TRACING environment variable.\"\n",
    "assert \"LANGSMITH_API_KEY\" in os.environ, \"Please set the LANGSMITH_API_KEY environment variable.\"\n",
    "assert \"PROJECT_ID\" in os.environ, \"Please set the PROJECT_ID environment variable.\"\n",
    "assert \"LOCATION\" in os.environ, \"Please set the LOCATION environment variable.\"\n",
    "assert \"DATASET\" in os.environ, \"Please set the DATASET environment variable.\"\n",
    "assert \"TABLE\" in os.environ, \"Please set the TABLE environment variable.\"\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\") \n",
    "LOCATION = os.getenv(\"LOCATION\") \n",
    "DATASET = os.getenv(\"DATASET\") \n",
    "TABLE = os.getenv(\"TABLE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2f1c55-a082-4397-89d7-86bf7792d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"llm-studies\"\n",
    "LOCATION = \"us-central1\"\n",
    "DATASET = \"blog_embeddings\"\n",
    "TABLE = \"rag_embeddings_s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c0c9ea-fe6d-457d-a813-90800f4f2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = VertexAIEmbeddings(model=\"textembedding-gecko@latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00f7952-6c84-4630-a662-da489c255157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery table llm-studies.blog_embeddings.rag_embeddings_s initialized/validated as persistent storage. Access via BigQuery console:\n",
      " https://console.cloud.google.com/bigquery?project=llm-studies&ws=!1m5!1m4!4m3!1sllm-studies!2sblog_embeddings!3srag_embeddings_s\n"
     ]
    }
   ],
   "source": [
    "vector_store = BigQueryVectorStore(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_name=DATASET,\n",
    "    table_name=TABLE,\n",
    "    location=LOCATION,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7c0c0e-3f25-4def-bc28-c875a73b8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2274302a-272d-41d0-9bea-f79b1de8aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8566336-ea60-4fe1-b36f-f61ccd80f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21494e8c-0eff-4b27-9c2b-95d8949ca88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd774d7-dc7b-4451-8af6-61ae87f48ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f363e75-b9ad-4116-a2c1-e2fd57876bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84795ad6-8bc3-4d23-acd5-102e79beecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = ToolNode([retrieve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa77685-614a-4ed2-8237-3cdb16ff9a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2c02e6-bcf1-42ef-9811-b41959eb8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3acc14ff-66f8-4251-9bf6-5212465db5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (ce5ea8be-ba2b-4eb1-ab0a-9aba90b978c8)\n",
      " Call ID: ce5ea8be-ba2b-4eb1-ab0a-9aba90b978c8\n",
      "  Args:\n",
      "    query: Dennett eliminativism\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'doc_id': 'e97bcd039fe34d2db3f497bbb900567a', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html', 'score': 0.7865426826423472}\n",
      "Content: disputa entre dualismo e materialismo, ambas as teses muito difíceis de serem\n",
      "defendidas em sua totalidade. Com a atualização dos termos mente e corpo para\n",
      "mente e cérebro, mais especificamente.\n",
      "Naturalismo e linguagem (p. 18).\n",
      "Dennett adota uma postura naturalista, dada sua filiação a Quine, enxergando\n",
      "que os problemas podem ser resolvidos pela ciência, no sentido do naturalismo\n",
      "científico[xi].\n",
      "Enfatizando o papel da linguagem em tal semântica, cabe aludirmos a como Ryle\n",
      "trata o tema, de maneira deflacionária[xii]. Resumidamente,\n",
      "cotidianamente utilizamos a expressão “na” cabeça metaforicamente, por exemplo,\n",
      "ao dizermos: “fiz aquela conta de cabeça”. Ocorre que, de fato, na cabeça há o\n",
      "cérebro, há sangue e pode haver óculos ou chapéu. Mas, ainda assim, é\n",
      "preferível que se use “na cabeça” do que na “mente” já que essa palavra vem\n",
      "carregada de ontologia, como um lugar estranho, mas cujo significado poderia\n",
      "ser simplificado se dispensássemos seu uso.\n",
      "Matematização da vida e a questão\n",
      "\n",
      "Source: {'doc_id': 'd11bffe050e54759be7cce0ff070a19a', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html', 'score': 0.7904954200015895}\n",
      "Content: intencionais que tratam do seu significado e termos não intencionais, regidos\n",
      "pela ciência natural. Conceitualmente, se aproximam da distinção de Frege de\n",
      "sentido e referência, ou seja, a extensão é a coisa e a intensão é o\n",
      "significado da coisa[xiv]. Mas é nessa distinção\n",
      "que reside o problema da psicologia, porque acaba sendo um discurso permeado\n",
      "pela vagueza, porque, como os termos significam, o significado é dependente do\n",
      "contexto. Para que o discurso psicológico se tornasse científico, ele teria que\n",
      "renunciar à intencionalidade com “s”, que é exatamente os termos que estão presentes\n",
      "no seu discurso.\n",
      "Domínio do virtual (p. 22).\n",
      "Qual que é a solução do Dennett? Vamos investigar mais detidamente como\n",
      "Teixeira, mas parece que Dennett passa essa conceituação para o domínio do\n",
      "virtual, por exemplo, falar da mente como algo virtual, que estaria no campo do\n",
      "intencional com “s”, mas que não teria existência própria, ou seja, é como se\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Daniel Dennett adota uma postura naturalista e parece conceituar a mente como algo virtual, situando-a no campo do intencional, mas sem existência própria. Essa abordagem sugere uma possível inclinação para o eliminativismo em relação à mente como uma entidade separada.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Dennett é um eliminativista?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}, {\"role\": \"system\", \"content\": \"Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c87d224-2ed1-49df-a2a9-a01bffbec620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (8a92829e-e2da-4769-bc97-f97dbfc53592)\n",
      " Call ID: 8a92829e-e2da-4769-bc97-f97dbfc53592\n",
      "  Args:\n",
      "    query: eliminativismo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'doc_id': '334d2e759817483d92a3d6b758bc1f6d', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html', 'score': 0.8559685179973763}\n",
      "Content: (p. 13). Parece que o materialismo trata o mental como algo\n",
      "apenas cerebral. Porém, não podemos nos privar da consciência, segundo\n",
      "Chalmers. De outro modo, seríamos zumbis[iv], ou seja, pessoas que\n",
      "andam por aí sem estar exatamente consciente do que fazem. Para Chalmers, há\n",
      "consciência e ela é um fenômeno irredutível no mundo, assim, com o tempo,\n",
      "espaço e outras coisas[v]. Dennett se insere nesse\n",
      "campo trazendo a visão de que é possível elucidar o que é a consciência pela\n",
      "investigação científica, pela neurociência, ou seja, “abrindo” o cérebro para\n",
      "ver o que tem dentro. Ou, enfim, pela evolução dos estudos de imagens cerebrais[vi]. Ora, essa linha de\n",
      "investigação pode abalar o campo filosófico já que a filosofia, pela sua\n",
      "primazia, trata os temas de maneira conceitual e, voltando nosso olhar\n",
      "estritamente para a ciência como ferramenta para resolução das questões,\n",
      "poderia não sobrar espaço para a reflexão filosófica (p. 15).\n",
      "Estudo da mente.\n",
      "\n",
      "Source: {'doc_id': 'ee7e2ab2cf78432aafd8070c013f06e3', 'source': 'https://www.reflexoesdofilosofo.blog.br/2024/08/a-terceira-margem-do-rio.html', 'score': 0.8684254539305748}\n",
      "Content: Sobre filosofia da mente, com uma pitada de ceticismo,\n",
      "linguagem e que tais[i]\n",
      "Mote. Vamos tentar\n",
      "investigar se, quando Dennett assume uma postura perante a linguagem comum e\n",
      "outra perante a linguagem científica, se ele está em uma postura cética. A postura\n",
      "cética é aquela que nos deixa viver da seguinte forma: “eu sei que tem um problema\n",
      "ali, mas eu consigo conviver com ele”[ii]. Até se aproxima de uma\n",
      "postura existencial, a lá Camus: “eu não tenho garantias de nada, tudo é\n",
      "muito misterioso, devo me matar?”. Ora, a postura cética não deixa de estar\n",
      "associada à linguagem, pois devemos evitar termos ou os parafrasear, como vamos\n",
      "ver com a substituição de “mente” por “cabeça” em asserções como: “o que tenho\n",
      "na mente?” e “O que tenho na cabeça?”.\n",
      "Consciência[iii]\n",
      "(p. 13). Parece que o materialismo trata o mental como algo\n",
      "apenas cerebral. Porém, não podemos nos privar da consciência, segundo\n",
      "Chalmers. De outro modo, seríamos zumbis[iv], ou seja, pessoas que\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Não tenho contexto suficiente para responder a essa pergunta.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Me fale quem é eliminativista\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}, {\"role\": \"system\", \"content\": \"Você é um tutor de filosofia e deve trazer as respostas baseadas na teorias encontradas nos textos, sejam de autores ou termos\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6c5e8c-3be3-46d9-b753-bbdb8adb3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bd3a3-cc0c-4c3f-be89-27955b57858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d4c9e-2900-4190-8867-f90a3fc58971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
